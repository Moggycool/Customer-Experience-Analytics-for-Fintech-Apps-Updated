{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Task 2 — Sentiment and Thematic Analysis (Fintech App Reviews)\n",
                "\n",
                "This notebook satisfies the Task‑2 requirements:\n",
                "\n",
                "## Sentiment\n",
                "- Model: `distilbert-base-uncased-finetuned-sst-2-english`\n",
                "- Output: `p_pos`, `p_neg`, signed `sentiment_score = p_pos - p_neg`\n",
                "- Labeling with **neutral margin**: if `|p_pos - p_neg| < margin` → `NEUTRAL`\n",
                "- Aggregations: by **bank**, and by **bank × rating**\n",
                "\n",
                "## Themes\n",
                "- Keyword extraction with **TF‑IDF** (1–2 grams)\n",
                "- Manual/rule‑based clustering into **3–5 themes per bank**\n",
                "- Example reviews per theme\n",
                "\n",
                "## Outputs\n",
                "Written to `data/processed/task2/`:\n",
                "- `reviews_task2_scored.csv`\n",
                "- `task2_sentiment_by_bank.csv`\n",
                "- `task2_sentiment_by_bank_rating.csv`\n",
                "- `task2_keywords_tfidf_by_bank.csv`\n",
                "- `task2_theme_examples.csv`\n",
                "\n",
                "---\n",
                "\n",
                "## Important (your setup)\n",
                "You said you’re using **`PYTHONPATH=src`**. This notebook therefore imports modules as:\n",
                "\n",
                "- `from bank_reviews... import ...`\n",
                "\n",
                "If any import fails, the notebook falls back to self‑contained implementations so you can still deliver results.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "from __future__ import annotations\n",
                "\n",
                "import sys\n",
                "from pathlib import Path\n",
                "\n",
                "import pandas as pd\n",
                "\n",
                "# --- Resolve project root (repo root) ---\n",
                "# notebooks/01_task1_scrape_and_clean.ipynb -> project root assumed to be parent of notebooks/\n",
                "PROJECT_ROOT = Path.cwd()\n",
                "# If running from within notebooks/ directory, go one level up\n",
                "if PROJECT_ROOT.name == \"notebooks\":\n",
                "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
                "\n",
                "print(\"PROJECT_ROOT:\", PROJECT_ROOT.resolve())\n",
                "\n",
                "# --- Ensure `src/` is on sys.path so `import bank_reviews` works ---\n",
                "SRC_DIR = PROJECT_ROOT / \"src\"\n",
                "if SRC_DIR.exists() and str(SRC_DIR) not in sys.path:\n",
                "    sys.path.insert(0, str(SRC_DIR))\n",
                "\n",
                "\n",
                "import re\n",
                "import hashlib\n",
                "from dataclasses import dataclass\n",
                "\n",
                "import numpy as np\n",
                "\n",
                "\n",
                "pd.set_option('display.max_columns', 200)\n",
                "pd.set_option('display.width', 140)\n",
                "\n",
                "# Heavy deps used only for sentiment; OK if they are installed via requirements-nlp.txt\n",
                "HAS_TRANSFORMERS = True\n",
                "try:\n",
                "    from transformers import pipeline\n",
                "except Exception as e:\n",
                "    HAS_TRANSFORMERS = False\n",
                "    print('Transformers not importable. Install torch + transformers for distilBERT sentiment.')\n",
                "    print('Error:', e)\n",
                "\n",
                "from sklearn.feature_extraction.text import TfidfVectorizer"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 0) Prefer project modules (`bank_reviews.*`) when available\n",
                "\n",
                "Because you run with `PYTHONPATH=src`, these imports should work.\n",
                "\n",
                "If they don’t (e.g., wrong working directory), the notebook uses fallbacks.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "USE_PROJECT_MODULES = True\n",
                "\n",
                "try:\n",
                "    # utilities\n",
                "    from bank_reviews.utils.text import make_review_id as make_review_id_project\n",
                "    from bank_reviews.utils.text import normalize_text as normalize_text_project\n",
                "\n",
                "    # sentiment\n",
                "    from bank_reviews.nlp.sentiment import SentimentConfig as SentimentConfigProject\n",
                "    from bank_reviews.nlp.sentiment import add_sentiment_columns as add_sentiment_columns_project\n",
                "    from bank_reviews.nlp.sentiment import label_from_probs as label_from_probs_project\n",
                "\n",
                "    # themes\n",
                "    from bank_reviews.nlp.themes import ThemeConfig as ThemeConfigProject\n",
                "    from bank_reviews.nlp.themes import add_theme_columns as add_theme_columns_project\n",
                "\n",
                "    # keywords\n",
                "    from bank_reviews.nlp.keywords import top_keywords_by_bank as top_keywords_by_bank_project\n",
                "\n",
                "    # metrics\n",
                "    from bank_reviews.analysis.metrics import sentiment_aggregates_by_bank as sent_agg_by_bank_project\n",
                "    from bank_reviews.analysis.metrics import sentiment_aggregates_by_bank_rating as sent_agg_by_bank_rating_project\n",
                "\n",
                "    # examples (if your project has it)\n",
                "    from bank_reviews.analysis.scenarios import sample_theme_examples as sample_theme_examples_project\n",
                "\n",
                "    print('Using project modules: bank_reviews.*')\n",
                "\n",
                "except Exception as e:\n",
                "    USE_PROJECT_MODULES = False\n",
                "    print('Could not import project modules; using fallback implementations.')\n",
                "    print('Error:', e)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1) Paths & load Task‑1 cleaned data\n",
                "\n",
                "Expected input: `data/processed/reviews_task1_clean.csv`\n",
                "\n",
                "Columns: `review, rating, date, bank, source`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "PROJECT_ROOT = Path.cwd()\n",
                "if PROJECT_ROOT.name == \"notebooks\":\n",
                "    PROJECT_ROOT = PROJECT_ROOT.parent\n",
                "\n",
                "IN_CSV = PROJECT_ROOT / \"data\" / \"processed\" / \"reviews_task1_clean.csv\"\n",
                "OUT_DIR = PROJECT_ROOT / \"data\" / \"processed\" / \"task2\"\n",
                "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
                "\n",
                "\n",
                "print('Project root:', PROJECT_ROOT)\n",
                "print('Input CSV:', IN_CSV, 'exists=', IN_CSV.exists())\n",
                "print('Output dir:', OUT_DIR)\n",
                "\n",
                "df = pd.read_csv(IN_CSV)\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "required_cols = {'review','rating','date','bank','source'}\n",
                "missing = required_cols - set(df.columns)\n",
                "if missing:\n",
                "    raise ValueError(f'Missing required columns: {missing}. Found: {list(df.columns)}')\n",
                "\n",
                "df = df.copy()\n",
                "df['review'] = df['review'].astype(str)\n",
                "df['bank'] = df['bank'].astype(str)\n",
                "df['source'] = df['source'].astype(str)\n",
                "df['date'] = df['date'].astype(str)\n",
                "df['rating'] = pd.to_numeric(df['rating'], errors='coerce')\n",
                "\n",
                "print('Rows:', len(df))\n",
                "df[['bank','source','rating']].value_counts().head(10)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2) Create deterministic `review_id`\n",
                "\n",
                "We use your project’s `make_review_id()` if available; otherwise fallback SHA‑1 over:\n",
                "\n",
                "`bank||source||date||rating||review`\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def make_review_id_fallback(*, review: str, bank: str, source: str, date: str, rating: float | int | str) -> str:\n",
                "    raw = f\"{bank}||{source}||{date}||{rating}||{review}\"\n",
                "    return hashlib.sha1(raw.encode('utf-8')).hexdigest()\n",
                "\n",
                "def normalize_text_fallback(s: str) -> str:\n",
                "    s = str(s).strip()\n",
                "    s = re.sub(r\"\\s+\", \" \", s)\n",
                "    return s\n",
                "\n",
                "make_review_id = make_review_id_project if USE_PROJECT_MODULES else make_review_id_fallback\n",
                "normalize_text = normalize_text_project if USE_PROJECT_MODULES else normalize_text_fallback\n",
                "\n",
                "df['review_id'] = [\n",
                "    make_review_id(review=r, bank=b, source=s, date=d, rating=rt)\n",
                "    for r,b,s,d,rt in zip(df['review'], df['bank'], df['source'], df['date'], df['rating'])\n",
                "]\n",
                "\n",
                "df[['review_id','bank','rating','review']].head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3) Sentiment analysis (distilBERT)\n",
                "\n",
                "Preferred path:\n",
                "- Use your project’s `add_sentiment_columns(df, SentimentConfig())`\n",
                "\n",
                "Fallback path:\n",
                "- Run `transformers.pipeline(..., top_k=None)` and compute neutral labels via margin.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Fallback implementation (only used if project module not available)\n",
                "NEUTRAL_MARGIN = 0.15\n",
                "BATCH_SIZE = 32\n",
                "MODEL_NAME = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
                "\n",
                "def label_from_probs_fallback(p_pos: float, p_neg: float, neutral_margin: float = NEUTRAL_MARGIN) -> str:\n",
                "    if abs(p_pos - p_neg) < neutral_margin:\n",
                "        return 'NEUTRAL'\n",
                "    return 'POSITIVE' if p_pos > p_neg else 'NEGATIVE'\n",
                "\n",
                "def add_sentiment_columns_fallback(df_in: pd.DataFrame) -> pd.DataFrame:\n",
                "    if not HAS_TRANSFORMERS:\n",
                "        raise RuntimeError('Transformers not available. Install torch + transformers.')\n",
                "\n",
                "    clf = pipeline(\n",
                "        'sentiment-analysis',\n",
                "        model=MODEL_NAME,\n",
                "        device=-1,\n",
                "        top_k=None,  # replaces deprecated return_all_scores=True\n",
                "    )\n",
                "\n",
                "    texts = df_in['review'].astype(str).map(normalize_text).tolist()\n",
                "    p_pos_list, p_neg_list, score_list, label_list = [], [], [], []\n",
                "\n",
                "    for i in range(0, len(texts), BATCH_SIZE):\n",
                "        batch = texts[i:i+BATCH_SIZE]\n",
                "        results = clf(batch)\n",
                "        for r in results:\n",
                "            score_map = {d['label'].upper(): float(d['score']) for d in r}\n",
                "            p_pos = score_map.get('POSITIVE', 0.0)\n",
                "            p_neg = score_map.get('NEGATIVE', 0.0)\n",
                "            s = p_pos - p_neg\n",
                "            lab = label_from_probs_fallback(p_pos, p_neg, NEUTRAL_MARGIN)\n",
                "\n",
                "            p_pos_list.append(p_pos)\n",
                "            p_neg_list.append(p_neg)\n",
                "            score_list.append(s)\n",
                "            label_list.append(lab)\n",
                "\n",
                "    out = df_in.copy()\n",
                "    out['p_pos'] = p_pos_list\n",
                "    out['p_neg'] = p_neg_list\n",
                "    out['sentiment_score'] = score_list\n",
                "    out['sentiment_label'] = label_list\n",
                "    return out\n",
                "\n",
                "if USE_PROJECT_MODULES:\n",
                "    # Uses your configured model + neutral margin in SentimentConfig\n",
                "    df = add_sentiment_columns_project(df, SentimentConfigProject())\n",
                "    label_from_probs = label_from_probs_project\n",
                "else:\n",
                "    df = add_sentiment_columns_fallback(df)\n",
                "    label_from_probs = label_from_probs_fallback\n",
                "\n",
                "df[['sentiment_label','sentiment_score','p_pos','p_neg']].head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# KPI: sentiment coverage (target 90%+)\n",
                "coverage = df['sentiment_label'].notna().mean()\n",
                "print('Sentiment coverage:', round(coverage * 100, 2), '%')\n",
                "df['sentiment_label'].value_counts(dropna=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4) Aggregate sentiment by bank and rating\n",
                "\n",
                "Preferred path: use your `bank_reviews.analysis.metrics` functions.\n",
                "\n",
                "Fallback path: compute groupby aggregates in-notebook.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def sent_agg_by_bank_fallback(df_in: pd.DataFrame) -> pd.DataFrame:\n",
                "    return (\n",
                "        df_in.groupby('bank', as_index=False)\n",
                "        .agg(\n",
                "            n_reviews=('review', 'size'),\n",
                "            mean_sentiment_score=('sentiment_score', 'mean'),\n",
                "            pos_rate=('sentiment_label', lambda s: (\n",
                "                s == 'POSITIVE').mean()),\n",
                "            neg_rate=('sentiment_label', lambda s: (\n",
                "                s == 'NEGATIVE').mean()),\n",
                "            neutral_rate=('sentiment_label', lambda s: (\n",
                "                s == 'NEUTRAL').mean()),\n",
                "        )\n",
                "    )\n",
                "\n",
                "\n",
                "def sent_agg_by_bank_rating_fallback(df_in: pd.DataFrame) -> pd.DataFrame:\n",
                "    return (\n",
                "        df_in.groupby(['bank', 'rating'], as_index=False)\n",
                "        .agg(\n",
                "            n_reviews=('review', 'size'),\n",
                "            mean_sentiment_score=('sentiment_score', 'mean'),\n",
                "            pos_rate=('sentiment_label', lambda s: (\n",
                "                s == 'POSITIVE').mean()),\n",
                "            neg_rate=('sentiment_label', lambda s: (\n",
                "                s == 'NEGATIVE').mean()),\n",
                "            neutral_rate=('sentiment_label', lambda s: (\n",
                "                s == 'NEUTRAL').mean()),\n",
                "        )\n",
                "    )\n",
                "\n",
                "\n",
                "if USE_PROJECT_MODULES:\n",
                "    sent_by_bank = sent_agg_by_bank_project(df)\n",
                "    sent_by_bank_rating = sent_agg_by_bank_rating_project(df)\n",
                "else:\n",
                "    sent_by_bank = sent_agg_by_bank_fallback(df)\n",
                "    sent_by_bank_rating = sent_agg_by_bank_rating_fallback(df)\n",
                "\n",
                "display(sent_by_bank.sort_values('mean_sentiment_score', ascending=False))\n",
                "display(sent_by_bank_rating.sort_values(['bank', 'rating']))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5) Keyword extraction (TF‑IDF 1–2 grams)\n",
                "\n",
                "Preferred path: `bank_reviews.nlp.keywords.top_keywords_by_bank`.\n",
                "\n",
                "Fallback path: compute TF‑IDF mean scores per bank.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def top_keywords_by_bank_fallback(\n",
                "    df_in: pd.DataFrame,\n",
                "    top_k: int = 30,\n",
                "    ngram_range=(1,2),\n",
                "    min_df: int = 2,\n",
                "    max_df: float = 0.95,\n",
                ") -> pd.DataFrame:\n",
                "    rows = []\n",
                "    for bank, dfg in df_in.groupby('bank'):\n",
                "        texts = dfg['review'].astype(str).map(normalize_text).tolist()\n",
                "        if len(texts) < 3:\n",
                "            continue\n",
                "        vec = TfidfVectorizer(\n",
                "            stop_words='english',\n",
                "            ngram_range=ngram_range,\n",
                "            min_df=min_df,\n",
                "            max_df=max_df,\n",
                "        )\n",
                "        X = vec.fit_transform(texts)\n",
                "        terms = np.array(vec.get_feature_names_out())\n",
                "        scores = np.asarray(X.mean(axis=0)).ravel()\n",
                "        idx = np.argsort(scores)[::-1][:top_k]\n",
                "        for rank, j in enumerate(idx, start=1):\n",
                "            rows.append({\n",
                "                'bank': bank,\n",
                "                'rank': rank,\n",
                "                'term': terms[j],\n",
                "                'tfidf_mean': float(scores[j]),\n",
                "                'n_docs': len(texts),\n",
                "            })\n",
                "    return pd.DataFrame(rows)\n",
                "\n",
                "if USE_PROJECT_MODULES:\n",
                "    kw_by_bank = top_keywords_by_bank_project(df, top_k=30)\n",
                "else:\n",
                "    kw_by_bank = top_keywords_by_bank_fallback(df, top_k=30)\n",
                "\n",
                "kw_by_bank.head(25)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6) Theme assignment (3–5 themes)\n",
                "\n",
                "Preferred path: use your `bank_reviews.nlp.themes.add_theme_columns`.\n",
                "\n",
                "Fallback path: rule-based lexicon scoring (weights: bigrams=2, unigrams=1) and assign:\n",
                "- `theme_primary`\n",
                "- `themes` (up to 2)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "THEME_LEXICON_FALLBACK = {\n",
                "    'ACCOUNT_ACCESS': [\n",
                "        'login', 'log in', 'sign in', 'signin', 'password', 'pin', 'otp', 'verification', 'biometric', 'fingerprint'\n",
                "    ],\n",
                "    'TXN_PERFORMANCE': [\n",
                "        'transfer', 'send money', 'transaction', 'pending', 'failed', 'failure', 'slow', 'delay', 'reversal', 'charged', 'fee', 'debit', 'credit'\n",
                "    ],\n",
                "    'STABILITY_BUGS': [\n",
                "        'crash', 'crashes', 'bug', 'bugs', 'freeze', 'frozen', 'hang', 'stuck', 'error', 'not working', 'keeps stopping'\n",
                "    ],\n",
                "    'UX_UI': [\n",
                "        'ui', 'ux', 'interface', 'design', 'layout', 'navigation', 'update', 'upgrade', 'easy to use', 'user friendly'\n",
                "    ],\n",
                "    'SUPPORT_SERVICE': [\n",
                "        'support', 'customer service', 'call center', 'agent', 'help', 'response', 'respond', 'no one', 'branch'\n",
                "    ],\n",
                "}\n",
                "\n",
                "def theme_scores_fallback(text: str, lexicon: dict[str, list[str]]) -> dict[str, float]:\n",
                "    t = ' ' + normalize_text(text).lower() + ' '\n",
                "    scores = {k: 0.0 for k in lexicon}\n",
                "    for theme, phrases in lexicon.items():\n",
                "        for p in phrases:\n",
                "            p2 = p.strip().lower()\n",
                "            if not p2:\n",
                "                continue\n",
                "            w = 2.0 if ' ' in p2 else 1.0\n",
                "            if p2 in t:\n",
                "                scores[theme] += w\n",
                "    return scores\n",
                "\n",
                "def assign_themes_fallback(text: str, lexicon: dict[str, list[str]], top_n: int = 2, min_score: float = 1.0) -> tuple[str | None, str]:\n",
                "    sc = theme_scores_fallback(text, lexicon)\n",
                "    items = sorted(sc.items(), key=lambda kv: kv[1], reverse=True)\n",
                "    items = [(k,v) for k,v in items if v >= min_score]\n",
                "    if not items:\n",
                "        return None, ''\n",
                "    primary = items[0][0]\n",
                "    top = [k for k,_ in items[:top_n]]\n",
                "    return primary, '|'.join(top)\n",
                "\n",
                "if USE_PROJECT_MODULES:\n",
                "    df = add_theme_columns_project(df, ThemeConfigProject())\n",
                "else:\n",
                "    primary, themes = [], []\n",
                "    for txt in df['review'].astype(str):\n",
                "        p, t = assign_themes_fallback(txt, THEME_LEXICON_FALLBACK, top_n=2, min_score=1.0)\n",
                "        primary.append(p)\n",
                "        themes.append(t)\n",
                "    df['theme_primary'] = primary\n",
                "    df['themes'] = themes\n",
                "\n",
                "df[['bank','rating','theme_primary','themes','review']].head(10)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# KPI: 3+ themes per bank\n",
                "theme_counts = (\n",
                "    df.dropna(subset=['theme_primary'])\n",
                "      .groupby('bank')['theme_primary']\n",
                "      .nunique()\n",
                "      .rename('n_unique_themes')\n",
                "      .reset_index()\n",
                ")\n",
                "theme_counts"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 7) Examples per theme per bank\n",
                "\n",
                "Preferred: `bank_reviews.analysis.scenarios.sample_theme_examples`.\n",
                "\n",
                "Fallback: pick top 3 longer reviews per `(bank, theme_primary)`.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def sample_theme_examples_fallback(df_in: pd.DataFrame, n_per_theme: int = 3) -> pd.DataFrame:\n",
                "    d = df_in.dropna(subset=['theme_primary']).copy()\n",
                "    d['review_len'] = d['review'].astype(str).str.len()\n",
                "    d = d.sort_values(['bank','theme_primary','review_len'], ascending=[True, True, False])\n",
                "    out = (\n",
                "        d.groupby(['bank','theme_primary'], as_index=False)\n",
                "         .head(n_per_theme)\n",
                "         .loc[:, ['bank','theme_primary','review_id','rating','sentiment_label','sentiment_score','review']]\n",
                "    )\n",
                "    return out\n",
                "\n",
                "if USE_PROJECT_MODULES:\n",
                "    examples = sample_theme_examples_project(df, n_per_theme=3)\n",
                "else:\n",
                "    examples = sample_theme_examples_fallback(df, n_per_theme=3)\n",
                "\n",
                "examples.head(20)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 8) Save outputs to CSV\n",
                "\n",
                "Minimum essentials:\n",
                "- sentiment scores for **≥ 400 reviews**\n",
                "- **≥ 2 themes per bank** via keywords/themes\n",
                "\n",
                "KPIs:\n",
                "- sentiment scored for **90%+** reviews\n",
                "- **3+ themes per bank** with examples\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "out_reviews = OUT_DIR / 'reviews_task2_scored.csv'\n",
                "out_bank = OUT_DIR / 'task2_sentiment_by_bank.csv'\n",
                "out_bank_rating = OUT_DIR / 'task2_sentiment_by_bank_rating.csv'\n",
                "out_keywords = OUT_DIR / 'task2_keywords_tfidf_by_bank.csv'\n",
                "out_examples = OUT_DIR / 'task2_theme_examples.csv'\n",
                "\n",
                "# KPI checks\n",
                "sent_cov = df['sentiment_score'].notna().mean() if 'sentiment_score' in df.columns else 0.0\n",
                "n_scored = int(df['sentiment_score'].notna().sum()) if 'sentiment_score' in df.columns else 0\n",
                "print('Sentiment coverage:', round(sent_cov*100, 2), '%')\n",
                "print('N sentiment-scored reviews:', n_scored)\n",
                "\n",
                "theme_per_bank = (\n",
                "    df.dropna(subset=['theme_primary'])\n",
                "      .groupby('bank')['theme_primary']\n",
                "      .nunique()\n",
                ")\n",
                "print('Unique themes per bank:')\n",
                "print(theme_per_bank)\n",
                "\n",
                "# Write files\n",
                "df.to_csv(out_reviews, index=False)\n",
                "sent_by_bank.to_csv(out_bank, index=False)\n",
                "sent_by_bank_rating.to_csv(out_bank_rating, index=False)\n",
                "kw_by_bank.to_csv(out_keywords, index=False)\n",
                "examples.to_csv(out_examples, index=False)\n",
                "\n",
                "print('Wrote:')\n",
                "for p in [out_reviews, out_bank, out_bank_rating, out_keywords, out_examples]:\n",
                "    print(' -', p, 'exists=', p.exists())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "MMenv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.14.3"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
